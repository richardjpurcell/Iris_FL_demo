{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Iris Demo - Federated Learning\n",
        "In this notebook the Iris dataset and the model developed in the previous notebook will be used to train a model using federated learning. There will be 3 clients, each with their own partition of the Iris dataset. In each round a central server will request the individual client weights from the trained models and average them to create a general model. The weights from this general model are then shared back to each individual client."
      ],
      "metadata": {
        "id": "CsZNAOzBbEAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook strongly borrows from the examples at https://flower.dev"
      ],
      "metadata": {
        "id": "nV8k6WAhfKGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if using Google Colab\n",
        "!pip install -q flwr[simulation]"
      ],
      "metadata": {
        "id": "2ilQbK05y9RZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.common.typing import NDArrays, Scalar\n",
        "\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from typing import Dict\n",
        "from typing import Optional\n",
        "import os\n",
        "\n",
        "# Make TensorFlow logs less verbose\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
      ],
      "metadata": {
        "id": "wmquLIkPtt6i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_version = !python --version\n",
        "print(\n",
        "    f\"Training on {'GPU' if tf.config.get_visible_devices('GPU') else 'CPU'}\\\n",
        "    using TensorFlow {tf.__version__}, Flower {fl.__version__} and {python_version[0]}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lKhKoKnS38W",
        "outputId": "e36f70f1-6b9d-4297-fec9-17ecf12bdb58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CPU    using TensorFlow 2.12.0, Flower 1.4.0 and Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global variables\n",
        "NUM_CLIENTS = 3\n",
        "EPOCHS = 50\n",
        "ROUNDS = 5"
      ],
      "metadata": {
        "id": "YOFsMfFbTy8M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datasets():\n",
        "    \"\"\"Loads in the iris dataset from scikit-learn. The dataset is shuffled,\n",
        "    one-hot-encoded, divided into datasets for three clients, and arrays of \n",
        "    train and test sets are returned.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[List[DataLoader], List[DataLoader]\n",
        "        Local train datasets, and local test datasets\n",
        "    \"\"\"\n",
        "\n",
        "    #make some arrays to hold each clients data\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    # load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target.reshape(-1, 1)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "\n",
        "    # One-hot encode the target variable\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    y = encoder.fit_transform(y)\n",
        "\n",
        "    # Split the shuffled data into three equal sets\n",
        "    X_set, y_set = np.split(X, 3), np.split(y, 3)\n",
        "\n",
        "    # Separate features and labels for each set\n",
        "    X_client1, y_client1 = X_set[0], y_set[0]\n",
        "    X_client2, y_client2 = X_set[1], y_set[1]\n",
        "    X_client3, y_client3 = X_set[2], y_set[2]\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_client1_train, X_client1_test, y_client1_train, y_client1_test = train_test_split(\n",
        "        X_client1, y_client1, test_size=0.2, random_state=42\n",
        "        )\n",
        "    \n",
        "    X_train.append(X_client1_train)\n",
        "    y_train.append(y_client1_train)\n",
        "    X_test.append(X_client1_test)\n",
        "    y_test.append(y_client1_test)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_client2_train, X_client2_test, y_client2_train, y_client2_test = train_test_split(\n",
        "        X_client2, y_client2, test_size=0.2, random_state=42\n",
        "        )\n",
        "    \n",
        "    X_train.append(X_client2_train)\n",
        "    y_train.append(y_client2_train)\n",
        "    X_test.append(X_client2_test)\n",
        "    y_test.append(y_client2_test)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_client3_train, X_client3_test, y_client3_train, y_client3_test = train_test_split(\n",
        "        X_client3, y_client3, test_size=0.2, random_state=42\n",
        "        ) \n",
        "\n",
        "    X_train.append(X_client3_train)\n",
        "    y_train.append(y_client3_train)\n",
        "    X_test.append(X_client3_test)\n",
        "    y_test.append(y_client3_test)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test  "
      ],
      "metadata": {
        "id": "WMSM3KHaz0XS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the datasets\n",
        "trainloaders_x, trainloaders_y, testloaders_x, testloaders_y = datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj5-pwwN8Db8",
        "outputId": "6d8f5c9e-e837-4eee-c001-a7d4b8912f21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Flower client\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    \"\"\"A generic client object which can be instantiated.\n",
        "    \"\"\"\n",
        "    def __init__(self, cid, model, x_train, y_train, x_test, y_test):\n",
        "        self.cid = cid\n",
        "        self.model = model\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        \"\"\"Return the current local model parameters\"\"\"\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"Train the model on the local (train) data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        parameters: NDarrays \n",
        "            Model parameters (weights) received from the server\n",
        "        \n",
        "        config: Dict[str, Scalar]\n",
        "            Server based configuration (needed only if you require dynamically changing values).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        NDArrays\n",
        "            Updated model parameters\n",
        "        \n",
        "        \"\"\"\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=EPOCHS, verbose=2)\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        \"\"\"Evaluate model using the validation data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "         parameters: NDarrays \n",
        "            Model parameters (weights) received from the server\n",
        "        \n",
        "        config: Dict[str, Scalar]\n",
        "            Server based configuration (needed only if you require dynamically changing values).\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        loss : float\n",
        "            The evaluation loss of the model on the local dataset.\n",
        "        num_examples : int\n",
        "            The number of examples used for evaluation.\n",
        "        metrics : Dict[str, Scalar]\n",
        "            A dictionary mapping arbitrary string keys to values of\n",
        "            type bool, bytes, float, int, or str. It can be used to\n",
        "            communicate arbitrary values back to the server.\n",
        "        \"\"\"\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc = self.model.evaluate(self.x_test, self.y_test, verbose=2)\n",
        "        return loss, len(self.x_test), {\"accuracy\": acc}\n",
        "    "
      ],
      "metadata": {
        "id": "xU5B-e1I61FW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f7a13013"
      },
      "outputs": [],
      "source": [
        "#create a unique Flower client\n",
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    \"\"\"Create a Flower client representing a single entity/organization.\"\"\"\n",
        "\n",
        "    print(\"\\nThis is client: \", cid)\n",
        "\n",
        "    x_train_cid = trainloaders_x[int(cid)]\n",
        "    y_train_cid = trainloaders_y[int(cid)]\n",
        "    x_test_cid = testloaders_x[int(cid)]\n",
        "    y_test_cid = testloaders_y[int(cid)]\n",
        "\n",
        "    print(\"Loaded data for client: \", cid, \"\\n\")\n",
        "\n",
        "    # Load model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(16, input_shape=(4,), activation='relu'),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "        ])\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "    # Create and return client\n",
        "    print(\"\\nClient CID: \" + str(cid) + \" is done.\\n\")\n",
        "    return FlowerClient(cid, model, x_train_cid, y_train_cid, x_test_cid, y_test_cid)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"A simple averaging for the metrics found in history.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "CKPw6Q-ZSLZC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# instatiating a strategy, in this case FedAvg\n",
        "strategy=fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        ")\n",
        "\n",
        "# launches the simulation, and saves the loss and accuracy to a history object\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=ROUNDS),\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFUibIpg9_z4",
        "outputId": "41a6745a-943a-4c21-8de2-405c87d85d80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-06-12 16:54:44,811 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-06-12 16:54:51,233\tINFO worker.py:1636 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-12 16:54:54,439 | app.py:180 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7759567259.0, 'object_store_memory': 3879783628.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7759567259.0, 'object_store_memory': 3879783628.0}\n",
            "INFO flwr 2023-06-12 16:54:54,451 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-12 16:54:54,455 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "INFO flwr 2023-06-12 16:55:08,861 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-06-12 16:55:08,867 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-12 16:55:08,871 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-12 16:55:08,874 | server.py:218 | fit_round 1: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m This is client:  2\n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m Loaded data for client:  2 \n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m Client CID: 2 is done.\n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m This is client:  2\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Loaded data for client:  2 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Client CID: 2 is done.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 1/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 2s - loss: 2.1892 - accuracy: 0.3000 - 2s/epoch - 784ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 2/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 2.1261 - accuracy: 0.3000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 3/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 2.0595 - accuracy: 0.3000 - 10ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 4/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 2.0025 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 5/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.9447 - accuracy: 0.3000 - 11ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 6/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.8877 - accuracy: 0.3000 - 14ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 7/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.8312 - accuracy: 0.3000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 8/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.7784 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 9/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.7265 - accuracy: 0.3000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 10/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.6771 - accuracy: 0.3000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 11/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.6303 - accuracy: 0.3000 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 12/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5853 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 13/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5436 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 14/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5011 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 15/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.4630 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 16/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.4276 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 17/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3943 - accuracy: 0.3000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 18/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3610 - accuracy: 0.3000 - 23ms/epoch - 11ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 19/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3316 - accuracy: 0.3000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 20/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3041 - accuracy: 0.2500 - 15ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 21/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2788 - accuracy: 0.2250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 22/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2533 - accuracy: 0.2000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 23/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2298 - accuracy: 0.1500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 24/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2087 - accuracy: 0.1500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 25/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1890 - accuracy: 0.1500 - 13ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 26/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1698 - accuracy: 0.1250 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 27/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1506 - accuracy: 0.2250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 28/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1325 - accuracy: 0.3000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 29/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1148 - accuracy: 0.3500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 30/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0987 - accuracy: 0.4000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 31/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0822 - accuracy: 0.5250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 32/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0676 - accuracy: 0.5500 - 11ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 33/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0528 - accuracy: 0.6250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 34/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0396 - accuracy: 0.6250 - 22ms/epoch - 11ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 35/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0264 - accuracy: 0.6250 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 36/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0143 - accuracy: 0.6500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 37/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0024 - accuracy: 0.6500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 38/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9910 - accuracy: 0.6750 - 20ms/epoch - 10ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 39/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9807 - accuracy: 0.7000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 40/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9700 - accuracy: 0.7000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 41/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9594 - accuracy: 0.7000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 42/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9500 - accuracy: 0.7000 - 13ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 43/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9420 - accuracy: 0.7000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 44/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9343 - accuracy: 0.7250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 45/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9265 - accuracy: 0.7250 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 46/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9177 - accuracy: 0.7500 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 47/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9099 - accuracy: 0.7750 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 48/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9032 - accuracy: 0.7750 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 49/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8962 - accuracy: 0.8000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 50/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8903 - accuracy: 0.8000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m This is client:  0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Loaded data for client:  0 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Client CID: 0 is done.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 1/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 1s - loss: 1.8887 - accuracy: 0.4000 - 1s/epoch - 509ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 2/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.8430 - accuracy: 0.4000 - 11ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 3/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.7993 - accuracy: 0.4000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 4/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.7560 - accuracy: 0.4000 - 16ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 5/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.7124 - accuracy: 0.4000 - 11ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 6/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.6719 - accuracy: 0.4000 - 17ms/epoch - 9ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 7/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.6324 - accuracy: 0.4000 - 14ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 8/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5905 - accuracy: 0.4000 - 10ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 9/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5567 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 10/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.5180 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 11/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.4865 - accuracy: 0.4000 - 16ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 12/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.4515 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 13/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.4214 - accuracy: 0.4000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 14/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3910 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 15/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3624 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 16/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3331 - accuracy: 0.4000 - 11ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 17/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.3077 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 18/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2811 - accuracy: 0.4000 - 10ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 19/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2553 - accuracy: 0.4000 - 28ms/epoch - 14ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 20/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2316 - accuracy: 0.4000 - 10ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 21/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.2081 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 22/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1851 - accuracy: 0.4000 - 16ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 23/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1640 - accuracy: 0.4000 - 11ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 24/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1433 - accuracy: 0.4000 - 12ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 25/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1232 - accuracy: 0.4000 - 9ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 26/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.1053 - accuracy: 0.4000 - 17ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 27/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0871 - accuracy: 0.4000 - 11ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 28/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0706 - accuracy: 0.4000 - 24ms/epoch - 12ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 29/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0541 - accuracy: 0.4000 - 11ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 30/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0391 - accuracy: 0.4000 - 13ms/epoch - 6ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 31/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0252 - accuracy: 0.4000 - 10ms/epoch - 5ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 32/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 1.0100 - accuracy: 0.4000 - 14ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 33/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9982 - accuracy: 0.4000 - 17ms/epoch - 9ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 34/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9847 - accuracy: 0.4000 - 21ms/epoch - 11ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 35/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9717 - accuracy: 0.4000 - 16ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 36/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9604 - accuracy: 0.4000 - 9ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 37/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9490 - accuracy: 0.4000 - 15ms/epoch - 8ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 38/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9390 - accuracy: 0.4000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 39/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9289 - accuracy: 0.4250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 40/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9199 - accuracy: 0.4250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 41/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9122 - accuracy: 0.4250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 42/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.9046 - accuracy: 0.5000 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 43/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8970 - accuracy: 0.5250 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 44/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8894 - accuracy: 0.5750 - 15ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 45/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8819 - accuracy: 0.6000 - 13ms/epoch - 7ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 46/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8742 - accuracy: 0.6500 - 8ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 47/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8665 - accuracy: 0.6500 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 48/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8589 - accuracy: 0.7000 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 49/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8530 - accuracy: 0.7250 - 7ms/epoch - 4ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 50/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.8456 - accuracy: 0.7500 - 6ms/epoch - 3ms/step\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Client CID: 1 is done.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 1/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 2/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 3/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 4/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 5/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 6/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 7/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 8/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 9/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m 2/2 - 0s - loss: 1.7767 - accuracy: 0.2750 - 9ms/epoch - 5ms/step\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 10/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 11/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 12/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 13/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 14/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 15/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 16/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 17/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 18/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 19/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 20/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:16,543 | server.py:232 | fit_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-06-12 16:55:16,553 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-12 16:55:16,560 | server.py:168 | evaluate_round 1: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 22/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 23/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 24/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 25/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 26/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 27/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 28/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 29/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 30/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 31/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 32/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 33/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 34/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 35/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 36/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 37/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 38/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 39/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 40/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 41/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 42/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 43/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 44/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 45/50\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m This is client:  2\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m Loaded data for client:  2 \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 46/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 47/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 48/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 49/50\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:17,559 | server.py:182 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:17,569 | server.py:218 | fit_round 2: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Client CID: 2 is done.\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:20,578 | server.py:232 | fit_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:20,590 | server.py:168 | evaluate_round 2: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 45/50\u001b[32m [repeated 145x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28528)\u001b[0m 1/1 - 1s - loss: 0.6388 - accuracy: 0.7000 - 855ms/epoch - 855ms/step\u001b[32m [repeated 196x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28528)\u001b[0m This is client:  0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28528)\u001b[0m Loaded data for client:  0 \u001b[32m [repeated 7x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:22,741 | server.py:182 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:22,745 | server.py:218 | fit_round 3: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m \u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Client CID: 2 is done.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 12/50\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m 2/2 - 0s - loss: 0.6098 - accuracy: 0.8000 - 16ms/epoch - 8ms/step\u001b[32m [repeated 91x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m This is client:  0\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Loaded data for client:  0 \u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:28,171 | server.py:232 | fit_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:28,181 | server.py:168 | evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 3)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28528)\u001b[0m WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1ae11cb370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "DEBUG flwr 2023-06-12 16:55:29,230 | server.py:182 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:29,238 | server.py:218 | fit_round 4: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m \u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Client CID: 0 is done.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Epoch 13/50\u001b[32m [repeated 155x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m 2/2 - 0s - loss: 0.5569 - accuracy: 0.8250 - 8ms/epoch - 4ms/step\u001b[32m [repeated 181x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m This is client:  1\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28529)\u001b[0m Loaded data for client:  1 \u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:32,360 | server.py:232 | fit_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:32,370 | server.py:168 | evaluate_round 4: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 3 clients (out of 3)\n",
            "DEBUG flwr 2023-06-12 16:55:33,389 | server.py:182 | evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:33,393 | server.py:218 | fit_round 5: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m \u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Client CID: 2 is done.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=28528)\u001b[0m Epoch 11/50\u001b[32m [repeated 243x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-12 16:55:36,288 | server.py:232 | fit_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-12 16:55:36,301 | server.py:168 | evaluate_round 5: strategy sampled 3 clients (out of 3)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 3 clients (out of 3)\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe83997a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "DEBUG flwr 2023-06-12 16:55:37,266 | server.py:182 | evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 3 results and 0 failures\n",
            "INFO flwr 2023-06-12 16:55:37,270 | server.py:147 | FL finished in 28.396297485000105\n",
            "INFO:flwr:FL finished in 28.396297485000105\n",
            "INFO flwr 2023-06-12 16:55:37,279 | app.py:218 | app_fit: losses_distributed [(1, 0.8680046598116556), (2, 0.6690971851348877), (3, 0.5392269790172577), (4, 0.45218942562739056), (5, 0.3788420458634694)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.8680046598116556), (2, 0.6690971851348877), (3, 0.5392269790172577), (4, 0.45218942562739056), (5, 0.3788420458634694)]\n",
            "INFO flwr 2023-06-12 16:55:37,283 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-12 16:55:37,287 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.8333333333333334), (2, 0.6666666567325592), (3, 0.8333333333333334), (4, 0.8666666547457377), (5, 0.9666666587193807)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.8333333333333334), (2, 0.6666666567325592), (3, 0.8333333333333334), (4, 0.8666666547457377), (5, 0.9666666587193807)]}\n",
            "INFO flwr 2023-06-12 16:55:37,290 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-12 16:55:37,297 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print the history of the simulation to screen\n",
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyyZVRqNQiUR",
        "outputId": "6b0a838d-5338-427a-c8f4-566d5c40f08e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.8680046598116556\n",
              "\tround 2: 0.6690971851348877\n",
              "\tround 3: 0.5392269790172577\n",
              "\tround 4: 0.45218942562739056\n",
              "\tround 5: 0.3788420458634694\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.8333333333333334), (2, 0.6666666567325592), (3, 0.8333333333333334), (4, 0.8666666547457377), (5, 0.9666666587193807)]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m 1/1 - 0s - loss: 0.4859 - accuracy: 1.0000 - 285ms/epoch - 285ms/step\u001b[32m [repeated 189x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m This is client:  1\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=28529)\u001b[0m Loaded data for client:  1 \u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}